# robots.txt for Brushin.in - AI LinkedIn Post Generator
# Last updated: 2025-12-23
# Website: https://brushin.in

User-agent: *
Allow: /

# Optimize crawling for key pages
Allow: /about
Allow: /pricing
Allow: /testimonials
Allow: /faq
Allow: /contact
Allow: /blog
Allow: /blog/
Allow: /resources
Allow: /linkedin-hashtag-generator
Allow: /linkedin-engagement-calculator
Allow: /linkedin-post-templates
Allow: /linkedin-writing-tips

# Block admin and auth pages from indexing but allow crawling
Disallow: /auth/
Disallow: /dashboard/
Disallow: /profile/
Disallow: /admin/
Disallow: /api/

# Allow important files
Allow: /sitemap.xml
Allow: /robots.txt
Allow: /*.css
Allow: /*.js
Allow: /*.png
Allow: /*.jpg
Allow: /*.jpeg
Allow: /*.gif
Allow: /*.webp
Allow: /*.svg
Allow: /*.ico

# Sitemaps
Sitemap: https://brushin.in/sitemap.xml

# Specific Rules for Major Search Engines
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 2

User-agent: Twitterbot
Allow: /

User-agent: facebookexternalhit
Allow: /

# LinkedIn-related bots (important for our niche)
User-agent: LinkedInBot
Allow: /

# OpenAI bots for training (optional - can disallow if preferred)
User-agent: ChatGPT-User
Allow: /

User-agent: OpenAI-SearchBot
Allow: /

# Google bots
User-agent: Googlebot-Image
Allow: /

User-agent: Googlebot-News
Allow: /

User-agent: Googlebot-Video
Allow: /

# Social media crawlers
User-agent: Slackbot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: Telegram
Allow: /

# Generic crawl delay for other bots
Crawl-delay: 3

# Host directive (important for SEO)
Host: https://brushin.in

# Block AI training on sensitive content
User-agent: CCBot
Disallow: /dashboard/
Disallow: /profile/

User-agent: Claude-Web
Disallow: /dashboard/
Disallow: /profile/

User-agent: anthropic-ai
Disallow: /dashboard/
Disallow: /profile/

User-agent: Bytespider
Disallow: /dashboard/
Disallow: /profile/
